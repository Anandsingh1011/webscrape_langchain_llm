{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a724b24-7868-4ece-8c53-6b2ef58147ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain beautifulsoup4 requests chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ab3266-b5a9-4f49-965f-7cd10994ca0a",
   "metadata": {},
   "source": [
    "### Scrape the Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f4486-d559-4959-affc-3819cc3cd445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fa740-18c2-4542-99c9-f5da09c2c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def scrape_page(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "def get_all_links(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    links = set()\n",
    "    for a_tag in soup.find_all('a', href=True):\n",
    "        link = urljoin(url, a_tag['href'])\n",
    "        links.add(link)\n",
    "    return links\n",
    "\n",
    "def scrape_website(base_url):\n",
    "    visited = set()\n",
    "    to_visit = {base_url}\n",
    "    all_texts = []\n",
    "\n",
    "    while to_visit:\n",
    "        url = to_visit.pop()\n",
    "        if url not in visited:\n",
    "            visited.add(url)\n",
    "            print(f\"Scraping {url}\")\n",
    "            try:\n",
    "                text = scrape_page(url)\n",
    "                all_texts.append(text)\n",
    "                links = get_all_links(url)\n",
    "                to_visit.update(links - visited)\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping {url}: {e}\")\n",
    "\n",
    "    return all_texts\n",
    "\n",
    "base_url = \"https://example.com\"\n",
    "all_texts = scrape_website(base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6545384e-ea0a-4e01-9ffb-8790492c08af",
   "metadata": {},
   "source": [
    "### Chunk the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7154af72-db5e-4986-a0b8-be703c260b6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[0;32m      3\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m texts \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(\u001b[43mall_texts\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_texts' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(all_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d23570b-eb7b-49de-a448-d3179f9f7bb6",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b82eee8-573b-49b4-96f9-391306d55169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\199374\\AppData\\Local\\Temp\\ipykernel_17888\\3025778155.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m      3\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings()\n\u001b[1;32m----> 4\u001b[0m embedded_texts \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39membed_documents(\u001b[43mtexts\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'texts' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embedded_texts = embeddings.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb486bc-cf04-40c8-9f32-fbf18759f76b",
   "metadata": {},
   "source": [
    "### Store in Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead8b84b-f2d4-468c-b2c6-e66fe10507ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client = chromadb.Client(Settings(\n",
    "    chroma_db_impl=\"duckdb+parquet\",\n",
    "    persist_directory=\"./chroma_db\"\n",
    "))\n",
    "\n",
    "collection = client.create_collection(name=\"website_data\")\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    collection.add(\n",
    "        documents=[text],\n",
    "        metadatas=[{\"source\": f\"page_{i}\"}],\n",
    "        ids=[str(i)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0488edaa-7973-4480-99d2-ee6d6d6adf83",
   "metadata": {},
   "source": [
    "### Query the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd11552-7a86-4712-b58d-21427cb5f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the main topic of the website?\"\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "for result in results['documents']:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb09d670-e857-414e-8a36-c64564c1def3",
   "metadata": {},
   "source": [
    "### LangChain for Advanced Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c7ad42-25a0-4fe7-add4-182fcd133602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\199374\\AppData\\Local\\Temp\\ipykernel_17888\\2009851881.py:5: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm=OpenAI(),\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      4\u001b[0m qa \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[0;32m      5\u001b[0m     llm\u001b[38;5;241m=\u001b[39mOpenAI(),\n\u001b[0;32m      6\u001b[0m     chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m----> 7\u001b[0m     retriever\u001b[38;5;241m=\u001b[39m\u001b[43mcollection\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m response \u001b[38;5;241m=\u001b[39m qa\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the main topic of the website?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'collection' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=collection.as_retriever()\n",
    ")\n",
    "\n",
    "response = qa.run(\"What is the main topic of the website?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6094a6ff-1d79-4638-bdda-682b44c116ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
